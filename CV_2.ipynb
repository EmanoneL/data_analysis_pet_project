{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmanoneL/data_analysis_pet_project/blob/main/CV_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime numpy opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhEbccqE5s-N",
        "outputId": "54aa234f-be8d-4ec1-c49c-6e3484f1967f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Отображение результатов\n",
        "def draw_boxes(image, results, new_path):\n",
        "\n",
        "    class_names = ['pleased', 'angry']\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "\n",
        "    for box, score, class_id in results:\n",
        "        # Корректируем координаты\n",
        "        x1 = max(0, box[0])\n",
        "        y1 = max(0, box[1])\n",
        "        x2 = min(width, box[2])\n",
        "        y2 = min(height, box[3])\n",
        "\n",
        "\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Формируе метку с классом\n",
        "        class_name = class_names[class_id]\n",
        "        label = f\"{class_name}: {score:.2f}\"\n",
        "\n",
        "        # Рассчитываем размеры текста\n",
        "        font_scale = 0.5\n",
        "        thickness = 1\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        text_size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
        "\n",
        "        text_x, text_y = x1, y1 - 10\n",
        "        text_x = max(0, min(width - text_size[0], text_x))  # Корректируем x\n",
        "        text_y = max(text_size[1], text_y)  # Корректируем y\n",
        "\n",
        "\n",
        "        cv2.putText(image, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n",
        "\n",
        "    cv2.imwrite(new_path, image)\n",
        "    #cv2.imshow(\"Detections\", image)\n",
        "\n",
        "\n",
        "# def draw_boxes(image, results, class_names):\n",
        "#     height, width, _ = image.shape\n",
        "\n",
        "#     for box, confidence, class_id in results:\n",
        "#         # Корректируем координаты\n",
        "#         x1 = max(0, box[0])\n",
        "#         y1 = max(0, box[1])\n",
        "#         x2 = min(width, box[2])\n",
        "#         y2 = min(height, box[3])\n",
        "\n",
        "#         # Рисуем бокс\n",
        "#         cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "#         # Формируем метку с текстом\n",
        "#         class_name = class_names[class_id]\n",
        "#         label = f\"{class_name}: {confidence:.2f}\"\n",
        "\n",
        "#         # Рассчитываем размеры текста\n",
        "#         font_scale = 0.5\n",
        "#         thickness = 1\n",
        "#         font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "#         text_size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
        "\n",
        "#         text_x, text_y = x1, y1 - 10\n",
        "#         text_x = max(0, min(width - text_size[0], text_x))  # Корректируем x\n",
        "#         text_y = max(text_size[1], text_y)  # Корректируем y\n",
        "\n",
        "#         # Рисуем фон для текста\n",
        "#         cv2.rectangle(image, (text_x, text_y - text_size[1] - 2),\n",
        "#                       (text_x + text_size[0], text_y + 2), (0, 255, 0), -1)\n",
        "\n",
        "#         # Накладываем текст\n",
        "#         cv2.putText(image, label, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)\n"
      ],
      "metadata": {
        "id": "7KbmJjcR8LJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(output, confidence_threshold=0.1, nms_threshold=0.1):\n",
        "    detections = output[0]  # Убираем пакетный размер\n",
        "    num_predictions = detections.shape[2]\n",
        "\n",
        "    boxes, confidences, class_ids = [], [], []\n",
        "\n",
        "    for i in range(num_predictions):\n",
        "        detection = detections[:, :, i].flatten()\n",
        "        x, y, w, h = detection[0:4]\n",
        "        confidence = detection[4]\n",
        "        class_scores = detection[5:]\n",
        "\n",
        "        if confidence < confidence_threshold:\n",
        "            continue\n",
        "\n",
        "        class_id = np.argmax(class_scores)\n",
        "        class_score = class_scores[class_id]\n",
        "\n",
        "        if class_score > confidence_threshold:\n",
        "            x1 = int(x - w / 2)\n",
        "            y1 = int(y - h / 2)\n",
        "            x2 = int(x + w / 2)\n",
        "            y2 = int(y + h / 2)\n",
        "\n",
        "            print(f\"Valid box: [{x1}, {y1}, {x2}, {y2}], confidence={confidence}, class_id={class_id}\")\n",
        "\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
        "    results = []\n",
        "\n",
        "    if len(indices) > 0:\n",
        "        for i in indices.flatten():\n",
        "            results.append((boxes[i], confidences[i], class_ids[i]))\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "FQ8C6SNI8Iuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для подготовки изображения\n",
        "def preprocess_image(image_path, input_size):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    resized = cv2.resize(image, (input_size, input_size))\n",
        "    # Преобразование в формат NCHW и нормализация\n",
        "    image_data = resized.transpose((2, 0, 1)) / 255.0\n",
        "    image_data = np.expand_dims(image_data, axis=0).astype(np.float32)\n",
        "    return image, image_data\n"
      ],
      "metadata": {
        "id": "pBRDSZEv8Czw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Загрузка модели YOLOv11\n",
        "model_path = \"best.onnx\"\n",
        "session = ort.InferenceSession(model_path)\n",
        "\n",
        "# Вывод информации о входах и выходах модели\n",
        "print(\"Model inputs:\", session.get_inputs())\n",
        "print(\"Model outputs:\", session.get_outputs())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqMivFo63V9f",
        "outputId": "53a89687-8d2c-4b23-818c-61793082647a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model inputs: [<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7d4e71f8dd70>]\n",
            "Model outputs: [<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7d4e71f8fef0>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка изображения\n",
        "input_size = 640  # Размер входа модели (зависит от обучения)\n",
        "image, image_data = preprocess_image(\"test3.jpg\", input_size)\n",
        "\n",
        "# Выполнение модели\n",
        "input_name = session.get_inputs()[0].name\n",
        "output = session.run(None, {input_name: image_data})\n",
        "\n",
        "# Вывод результатов\n",
        "for i, out in enumerate(output):\n",
        "    print(f\"Output[{i}] shape: {np.array(out).shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7YncOC58Am0",
        "outputId": "7a1a12d1-9288-4eaa-8c7f-35b8c47a5481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output[0] shape: (1, 6, 8400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = postprocess(output)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9wzc5TV78q8K",
        "outputId": "fd120670-357f-4044-b916-4d9d0eee1b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_boxes(image, results, 'result.jpg')"
      ],
      "metadata": {
        "id": "o3_aiqSt89Ab"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1G2B09YBX4bfzG_k_gWX9o1uDL5TDLwm5",
      "authorship_tag": "ABX9TyMyLfupuecrL5D5HXRb2JHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}