{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmanoneL/data_analysis_pet_project/blob/main/desk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорт библиотек"
      ],
      "metadata": {
        "id": "gYtT7NOTzA64"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PMkciQXT3XH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # Для работы с DataFrame\n",
        "import numpy as np # Для математических операций с DataFrame\n",
        "import matplotlib.pyplot as plt # Для работы с графиками и гистограммами\n",
        "import scipy.stats as stats # Некоторые функции для работы со статистикой\n",
        "import seaborn as sns # Для ящика с усами\n",
        "from scipy.stats import kstest # Критерий Колмогорова-Смирнова\n",
        "from scipy.stats import chi2_contingency # Критерий хи-квадрат"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пользовательские функции"
      ],
      "metadata": {
        "id": "DWyOj7_ozJVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yujb8k4nhh9c"
      },
      "outputs": [],
      "source": [
        "# Формирует новый столбец(фичу) в DataFrame по данным из столбца price_doc\n",
        "def price_doc_to_class(df):\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    X['class'] = ''\n",
        "\n",
        "    X.loc[(y <= 3000000), 'class'] = 'cheap'\n",
        "    X.loc[(y > 3000000) & (y <= 11000000), 'class'] = 'normal'\n",
        "    X.loc[y > 11000000, 'class'] = 'expensive'\n",
        "\n",
        "    X = pd.concat([X, y], axis=1)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7HMYW1KnDHb"
      },
      "outputs": [],
      "source": [
        "# Проверяет близость к нормальному распределению для фичи по критерию Колмогорова-Смирнова\n",
        "def checkStandart(df, feature_name):\n",
        "  data = (df[feature_name] - df[feature_name].mean()) / df[feature_name].std()\n",
        "\n",
        "  # Выполняем K-S тест для проверки нормальности\n",
        "  stat, p_value = kstest(data, 'norm')\n",
        "  print(f'Statistic: {stat}, p-value: {p_value}')\n",
        "\n",
        "  # Интерпретация результата\n",
        "  alpha = 0.05\n",
        "  if p_value > alpha:\n",
        "      print('Распределение близко к нормальному (не отклоняем H0)')\n",
        "  else:\n",
        "      print('Распределение отличается от нормального (отклоняем H0)')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def breushPaganTest(X, y):\n",
        "  X_const = sm.add_constant(X)\n",
        "  model_sm = sm.OLS(y, X_const).fit()\n",
        "  test_stat, p_value, _, _ = het_breuschpagan(model_sm.resid, model_sm.model.exog)\n",
        "\n",
        "  print(f'Test Statistic: {test_stat}')\n",
        "  print(f'p-value: {p_value}')\n",
        "\n",
        "  if p_value < 0.05:\n",
        "      print(\"Отвергаем нулевую гипотезу: наличие гетероскедастичности.\")\n",
        "  else:\n",
        "      print(\"Не отвергаем нулевую гипотезу: гомоскедастичность сохраняется.\")"
      ],
      "metadata": {
        "id": "gU3lcEsoPogG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка данных"
      ],
      "metadata": {
        "id": "MW5KQNv4zNom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "zNPfkLlGM8cd",
        "outputId": "b2251422-577b-4d33-d0cb-6ff45a9de417"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-01736899354d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Загружаем файл в DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Выводим первые 10 результатов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('dataset.csv', index_col=0) # Загружаем файл в DataFrame\n",
        "df.head(10) # Выводим первые 10 результатов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuyLGk4EXjnb"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnutv9VuiXQY"
      },
      "source": [
        "Заметим сразу, что в выборке нет пропусков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ_ESjVevDES"
      },
      "source": [
        "**Описание датасета**\n",
        "\n",
        "* **full_sq** - общая площадь\n",
        "* **build_year** - год постройки\n",
        "* **price_doc** - цена квартиры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-5ut5Dmbukk"
      },
      "source": [
        "#Дескриптивный анализ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYz0vNkeWElE"
      },
      "outputs": [],
      "source": [
        "df.hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPbuRrxKX4yX"
      },
      "outputs": [],
      "source": [
        "df['price_doc'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdo92coXYbIM"
      },
      "outputs": [],
      "source": [
        "df['full_sq'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsQr55ppYmYk"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=df['price_doc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAt6HYjzcGJa"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=df['full_sq'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aerGNPzicROM"
      },
      "outputs": [],
      "source": [
        "df = df[\n",
        "    (df['price_doc'] <= df['price_doc'].quantile(0.95))\n",
        "    & (df['full_sq'] <= df['full_sq'].quantile(0.95))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3o6pi6Bci0R"
      },
      "outputs": [],
      "source": [
        "df.hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVxFaguPxISC"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ki1Q6OJmiPm"
      },
      "outputs": [],
      "source": [
        "checkStandart(df, 'full_sq')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zVKzNUXnpym"
      },
      "outputs": [],
      "source": [
        "checkStandart(df, 'price_doc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqBt6a0HqPK6"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Применям ранговую корреляцию Спирмана, так как распределение не нормальное\n",
        "corr, p_value = spearmanr(df['price_doc'], df['full_sq'])\n",
        "print(f\"Spearman's correlation: {corr}, p-value: {p_value}\")\n",
        "\n",
        "# Интерпретация\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print('Корреляция значима (отклоняем H0)')\n",
        "else:\n",
        "    print('Корреляция незначима (не отклоняем H0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUxsF_4AibSO"
      },
      "outputs": [],
      "source": [
        "df2 = price_doc_to_class(df) # Добавляем категориальную переменную"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFHtBcB9hIbR"
      },
      "outputs": [],
      "source": [
        "# Строим таблицу сопряженности\n",
        "contingency_table = pd.crosstab(df2['build_type'], df2['class'])\n",
        "print(contingency_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYkjDpsEup1n"
      },
      "outputs": [],
      "source": [
        "# Критерий хи-квадрат для проверки статистической гипотезы о независимости этих переменных\n",
        "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(\"Expected frequencies:\\n\", expected)\n",
        "\n",
        "# Интерпретация результатов\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Отвергаем нулевую гипотезу - существует связь между переменными.\")\n",
        "else:\n",
        "    print(\"Не отвергаем нулевую гипотезу - связи между переменными не обнаружено.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регрессионный анализ\n"
      ],
      "metadata": {
        "id": "GWYoUwnNLXfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У нас есть корреляция между full_sq, build_type и price_doc\n",
        "Так как у нас есть категориальный признак, преобразуем его в несколько числовых с помощью метода one-hot\n"
      ],
      "metadata": {
        "id": "_0_eYYq9-bGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "nyTcMirm_jJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение признаков и целевой переменной\n",
        "X = df[['full_sq', 'build_type']]\n",
        "x = df['full_sq']\n",
        "y = df['price_doc']"
      ],
      "metadata": {
        "id": "8QqEO0fVCWbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(df, 'build_type',dtype=int)\n",
        "X"
      ],
      "metadata": {
        "id": "Gj0CdB1mBrQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение данных (например, 80% обучающая, 20% тестовая)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "CzOkidQ3_OvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Добавляем константу для intercept\n",
        "x = sm.add_constant(x)\n",
        "\n",
        "# Создаем и обучаем модель OLS\n",
        "model = sm.OLS(y, x)\n",
        "results = model.fit()\n",
        "\n",
        "# Предсказанные значения и остатки\n",
        "predicted_values = results.fittedvalues\n",
        "residuals = results.resid\n",
        "\n",
        "# Строим график остатков\n",
        "plt.scatter(predicted_values, residuals)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Предсказанные значения')\n",
        "plt.ylabel('Остатки')\n",
        "plt.title('График остатков')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nKoyKJkq3dJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Гистограмма стандартизированных признаков\n",
        "# Рассчитываем стандартное отклонение остатков\n",
        "std_residuals = np.std(residuals)\n",
        "\n",
        "# Стандартизированные остатки\n",
        "standardized_residuals = residuals / std_residuals\n",
        "\n",
        "# Построение гистограммы стандартизированных остатков\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(standardized_residuals, kde=True, bins=30, color='skyblue')\n",
        "plt.xlabel('Стандартизированные остатки')\n",
        "plt.ylabel('Частота')\n",
        "plt.title('Гистограмма стандартизированных остатков')\n",
        "plt.axvline(0, color='red', linestyle='--')  # линия на уровне 0\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gi8gGnodNDNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results.summary()"
      ],
      "metadata": {
        "id": "iymVGk744ohw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "p-значение меньше, чем выбранный уровень значимости, это говорит о том, что коэффициенты являются значимыми\n",
        "\n",
        "Если p-значение (Prob F-statistic) меньше стандартного уровня значимости, это означает, что хотя бы одна из независимых переменных оказывает статистически значимое влияние на зависимую переменную.\n",
        "В данном случае p-значение чрезвычайно мало (меньше 0.05), что подтверждает, что модель регрессии в целом является статистически значимой"
      ],
      "metadata": {
        "id": "EFQqMynx-PTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Нормальность остатков**:\n",
        "\n",
        "Omnibus и Jarque-Bera (JB) — это тесты, которые проверяют гипотезу о нормальности распределения остатков.\n",
        "Omnibus: значение 17.270 с p-значением 0.000.\n",
        "Jarque-Bera (JB): значение 20.465 с p-значением 3.60e-05.\n",
        "Оба теста указывают на отклонение остатков от нормального распределения (p < 0.05), что может свидетельствовать о нарушении допущения нормальности остатков.\n",
        "\n",
        "**Автокорреляция остатков**:\n",
        "\n",
        "Durbin-Watson (DW) тест используется для проверки автокорреляции остатков. Значение DW равно 1.972, что близко к 2, и это указывает на отсутствие значительной автокорреляции (при 2 автокорреляция отсутствует).\n",
        "\n",
        "**Гетероскедастичность**:\n",
        "\n",
        "ниже проведен тест Бреуша-Пагана, который показал, что дисперсия остатков не является постоянной, следовательно, присутсвует гетероскедастичность\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AgeZqWWAAGEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intercept, slope = results.params\n",
        "print(f\"Уравнение регрессии: y = {intercept} + {slope} * X\")"
      ],
      "metadata": {
        "id": "AwwYMwr5L7Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "\n",
        "# Функция для вычисления VIF\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variable\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "\n",
        "vif_result = calculate_vif(x)\n",
        "\n",
        "print(vif_result)\n"
      ],
      "metadata": {
        "id": "nLiOD0ueD90u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нет признаков избыточности переменных среди независимых переменных, так как VIF для full_sq находится на приемлемом уровне.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WydV0xbOFkfZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}